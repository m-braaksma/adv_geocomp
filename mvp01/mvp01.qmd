---
title: "MVP 1"
subtitle: "Advanced Geocomputation"
author: 'Matt Braaksma'
toc: true
format: 
    html:
        theme: sandstone
        html-math-method: katex
        embed-resources: true
        code-fold: true
    pdf:  
        documentclass: article
        papersize: letter
number-sections: false
execute: 
    cache: true
jupyter: python3
---

## Description

imports

## Design Framework

- Problem: Write a 2-3 sentence description of the problem you are solving.
    - OpenStreetMap provides layer of land use/land cover data. How does this compare to land use/land cover data derived from remote sensing data?
- Solution: Write a 2-3 sentence description of the robust solution that would solve the problem. Note, this is not the MVP solution. This is the complete solution if you had unlimited resources.
    - Answering this question requires accessing both OSM LULC data and a remote sensing data set. Next a correspondence is required to ensure the proper classes are being compared. Then spatial correlation analysis can be conducted. Finally, other data could be included to determine whether the correlations are driving by other socioeconomic or geographic determinants. 
- Challenge: Write a 1-2 sentence description of the top-most challenge to create your solution.
    - Sourcing the data and ensuring that the different pieces work well together. 
- Spec list: Brainstorm all of the features/capabilities your solution will need. Rate each feature/capability on their value (how useful is it?) and effort (how much time to create it?). List your top 7 features and their rated value and effort as High, Medium, Low (H, M, L) for your spec.


| Spec  | Value (H, M, L) | Effort (H, M, L)| 
|---	|---	|---	|
| Get OSM data  	|   H	|   L	|
| Get remote sensing data  	|   H	|   M	|
|  Create class correspondence 	|   M	|   M	|
|  Rasterize OSM data  	|   H	|   H	|
|  Compare OSM and remote sensing rasters  	|   H	|   M	|

Review the spec list. Cross of features that are too high effort for too low value until you have a
list of features that can be implemented in 2 weeks. That is your MVP!
Success: Now that you have your MVP spec. What is the key metric for success? If you achieve
XYZ you know that your MVP was successful. Write 1 sentence outlining your 1 key metric.
Reflection: After you implement your MVP, write 6-7 sentences reflecting on your experiences in
developing and running your MVP. Was it successful? What did you learn? Would you have done
something differently if you were to repeat the project?

## Code

### Import modules
```{python}
from pyrosm import OSM
from pyrosm import get_data
import matplotlib.pyplot as plt

import osmnx as ox
import geopandas as gpd
from osgeo import gdal, ogr
import pygeoprocessing as pygeo
import os
```

```{python, get_mn}
# Get the geographic boundary for St. Louis County, Minnesota
gdf = ox.geocode_to_gdf("Lakeville, Minnesota, USA")
gdf_path = '/Users/mbraaksma/Files/advgeocomp2024/advgeocomp2024/mvp01/data/lakeville.gpkg'
# albers_crs = {
#     'proj': 'aea', 'lat_1': 29.5, 'lat_2': 45.5, 'lat_0': 23, 
#     'lon_0': -96, 'x_0': 0, 'y_0': 0, 'datum': 'WGS84', 'units': 'm', 'no_defs': True
# }
# gdf = gdf.to_crs(albers_crs)
gdf.to_file(gdf_path, driver='GPKG')
```

```{python}
# File paths
input_raster = '/Volumes/T7 Touch/Research/Reservation_Land/NLCD/raw/nlcd_2021_land_cover_l48_20230630/nlcd_2021_land_cover_l48_20230630.img'
input_vector = '/Users/mbraaksma/Files/advgeocomp2024/advgeocomp2024/mvp01/data/lakeville.gpkg'
output_raster = '/Users/mbraaksma/Files/base_data/lulc/nlcd/nlcd_clipped.tif'

# Open the raster
raster = gdal.Open(input_raster)

# Use gdal.Warp to clip raster with the vector file
gdal.Warp(
    output_raster,
    raster,
    format='GTiff',
    cutlineDSName=input_vector,  # Path to vector file
    cropToCutline=True,          # Only crop the raster to the extent of the vector
    dstNodata=-9999,             # Set nodata value for the output raster
)

# Close the dataset
raster = None
```

### Import OSM LULC #2

```{python, cache=TRUE}
gdf = ox.features_from_place("Lakeville, Minnesota, USA", tags = {"landuse": True})
gdf.explore(column='landuse')
```

### Import ESA LULC
```{python, cache=TRUE}
lulc_path = '/Users/mbraaksma/Files/base_data/lulc/nlcd/nlcd_clipped.tif'
lulc_data = gdal.Open(lulc_path)

lulc_array = lulc_data.GetRasterBand(1).ReadAsArray()

# Close the dataset
lulc_data = None

# Plot the raster data
plt.figure(figsize=(10, 8))
plt.imshow(lulc_array, cmap='viridis')  # Adjust colormap if needed
plt.colorbar(label='Raster Values')
plt.title('Raster Plot')
plt.show()
```

```{python}
# 1. Keep only polygons (Polygon or MultiPolygon)
gdf_polygons = gdf[gdf['geometry'].geom_type.isin(['Polygon', 'MultiPolygon'])]

# 2. Drop all columns except 'geometry' and 'landuse'
gdf_polygons = gdf_polygons[['geometry', 'landuse']]

# 3. Reset index to remove the multi-index structure
gdf_polygons = gdf_polygons.reset_index(drop=True)
```

```{python}
# Define the mapping from landuse to landuse_esa
landuse_to_landuse_esa = {
    "grass": 130,                # Grassland
    "residential": 190,          # Urban areas
    "commercial": 190,           # Urban areas
    "forest": 50,                # Tree cover, broadleaved, evergreen
    "farmland": 10,              # Cropland, rainfed
    "industrial": 190,           # Urban areas
    "farmyard": 10,              # Cropland, rainfed
    "religious": 190,            # Urban areas
    "recreation_ground": 130,    # Grassland
    "basin": 220,                # Permanent snow and ice or water-related
    "cemetery": 190,             # Urban areas
    "meadow": 130,               # Grassland
    "retail": 190,               # Urban areas
    "quarry": 200,               # Bare areas
    "plant_nursery": 10,         # Cropland, rainfed
    "brownfield": 200,           # Bare areas
    "greenfield": 10,            # Cropland, rainfed
    "construction": 200           # Bare areas
}

# Create a new column 'landuse_esa' in the GeoDataFrame
gdf_polygons['landuse_esa'] = gdf_polygons['landuse'].map(landuse_to_landuse_esa)

# Optional: Check the first few rows to verify the new column
print(gdf_polygons[['landuse', 'landuse_esa']].head())
gdf_path = '/Users/mbraaksma/Files/advgeocomp2024/advgeocomp2024/mvp01/data/lakeville_esa.gpkg'
gdf_polygons.to_file(gdf_path, driver='GPKG')
```

```{python}
import geopandas as gpd
import rasterio
from rasterio.features import rasterize
import numpy as np

# Load your GeoDataFrame
gdf_path = '/Users/mbraaksma/Files/advgeocomp2024/advgeocomp2024/mvp01/data/lakeville_esa.gpkg'
gdf = gpd.read_file(gdf_path)

# Load the existing raster to get its metadata
raster_path = '/Users/mbraaksma/Files/base_data/lulc/nlcd/nlcd_clipped.tif'
with rasterio.open(raster_path) as src:
    meta = src.meta
    transform = src.transform

# Reproject the GeoDataFrame if necessary
if gdf.crs != src.crs:
    gdf = gdf.to_crs(src.crs)

# Create an empty array for the new raster
out_array = np.zeros((meta['height'], meta['width']), dtype=np.float32)

# Prepare geometries and attributes for rasterization
geometries = [(geom, int(row.landuse_esa)) for _, row in gdf.iterrows() for geom in [row.geometry]]

# Print geometry information for debugging
print("Number of geometries:", len(geometries))

# Rasterize the geometries
rasterized = rasterize(
    geometries,
    out_shape=out_array.shape,
    transform=transform,
    fill=0,  # Fill value for no data
    all_touched=True,  # Rasterize all pixels touched by geometries
    dtype='float32'
)

# Check if the rasterized output contains any non-zero values
print("Unique values in rasterized output:", np.unique(rasterized))

# Update the metadata for the new raster
meta.update({'dtype': 'float32', 'count': 1})

# Write the rasterized output to a new file
output_raster_path = '/Users/mbraaksma/Files/base_data/lulc/nlcd/osm_lakeville_rasterio.tif'
with rasterio.open(output_raster_path, 'w', **meta) as dst:
    dst.write(rasterized, 1)

print("Rasterization completed successfully using Rasterio!")
```




::: {.callout-tip collapse="true"}
## Answer
:::